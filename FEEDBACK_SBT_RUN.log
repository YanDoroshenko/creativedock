$ sbt run
[info] Loading settings from plugins.sbt ...
[info] Loading project definition from /Users/jancajthaml/Repositories/CreativeDocs-PRS/creativedock/project
[info] Loading settings from build.sbt ...
[info] Set current project to creativedock (in build file:/Users/jancajthaml/Repositories/CreativeDocs-PRS/creativedock/)
[info] Packaging /Users/jancajthaml/Repositories/CreativeDocs-PRS/creativedock/target/scala-2.12/creativedock_2.12-0.1.jar ...
[info] Done packaging.
[info] Running com.github.yandoroshenko.creativedock.RestController
[run-main-0] INFO org.apache.kafka.clients.consumer.ConsumerConfig: ConsumerConfig values:
  auto.commit.interval.ms = 1000
  auto.offset.reset = latest
  bootstrap.servers = [localhost:9092]
  check.crcs = true
  client.id =
  connections.max.idle.ms = 540000
  enable.auto.commit = true
  exclude.internal.topics = true
  fetch.max.bytes = 52428800
  fetch.max.wait.ms = 500
  fetch.min.bytes = 1
  group.id = group
  heartbeat.interval.ms = 3000
  interceptor.classes = null
  internal.leave.group.on.close = true
  isolation.level = read_uncommitted
  key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
  max.partition.fetch.bytes = 1048576
  max.poll.interval.ms = 300000
  max.poll.records = 500
  metadata.max.age.ms = 300000
  metric.reporters = []
  metrics.num.samples = 2
  metrics.recording.level = INFO
  metrics.sample.window.ms = 30000
  partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
  receive.buffer.bytes = 65536
  reconnect.backoff.max.ms = 1000
  reconnect.backoff.ms = 50
  request.timeout.ms = 305000
  retry.backoff.ms = 100
  sasl.jaas.config = null
  sasl.kerberos.kinit.cmd = /usr/bin/kinit
  sasl.kerberos.min.time.before.relogin = 60000
  sasl.kerberos.service.name = null
  sasl.kerberos.ticket.renew.jitter = 0.05
  sasl.kerberos.ticket.renew.window.factor = 0.8
  sasl.mechanism = GSSAPI
  security.protocol = PLAINTEXT
  send.buffer.bytes = 131072
  session.timeout.ms = 10000
  ssl.cipher.suites = null
  ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
  ssl.endpoint.identification.algorithm = null
  ssl.key.password = null
  ssl.keymanager.algorithm = SunX509
  ssl.keystore.location = null
  ssl.keystore.password = null
  ssl.keystore.type = JKS
  ssl.protocol = TLS
  ssl.provider = null
  ssl.secure.random.implementation = null
  ssl.trustmanager.algorithm = PKIX
  ssl.truststore.location = null
  ssl.truststore.password = null
  ssl.truststore.type = JKS
  value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[run-main-0] INFO org.apache.kafka.common.utils.AppInfoParser: Kafka version : 1.0.1
[run-main-0] INFO org.apache.kafka.common.utils.AppInfoParser: Kafka commitId : c0518aa65f25317e
[run-main-0] INFO com.github.yandoroshenko.creativedock.kafka.MessagesConsumer$: Subscribing for topic messages
[run-main-0] INFO org.apache.kafka.clients.consumer.ConsumerConfig: ConsumerConfig values:
  auto.commit.interval.ms = 1000
  auto.offset.reset = latest
  bootstrap.servers = [localhost:9092]
  check.crcs = true
  client.id =
  connections.max.idle.ms = 540000
  enable.auto.commit = true
  exclude.internal.topics = true
  fetch.max.bytes = 52428800
  fetch.max.wait.ms = 500
  fetch.min.bytes = 1
  group.id = group
  heartbeat.interval.ms = 3000
  interceptor.classes = null
  internal.leave.group.on.close = true
  isolation.level = read_uncommitted
  key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
  max.partition.fetch.bytes = 1048576
  max.poll.interval.ms = 300000
  max.poll.records = 500
  metadata.max.age.ms = 300000
  metric.reporters = []
  metrics.num.samples = 2
  metrics.recording.level = INFO
  metrics.sample.window.ms = 30000
  partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
  receive.buffer.bytes = 65536
  reconnect.backoff.max.ms = 1000
  reconnect.backoff.ms = 50
  request.timeout.ms = 305000
  retry.backoff.ms = 100
  sasl.jaas.config = null
  sasl.kerberos.kinit.cmd = /usr/bin/kinit
  sasl.kerberos.min.time.before.relogin = 60000
  sasl.kerberos.service.name = null
  sasl.kerberos.ticket.renew.jitter = 0.05
  sasl.kerberos.ticket.renew.window.factor = 0.8
  sasl.mechanism = GSSAPI
  security.protocol = PLAINTEXT
  send.buffer.bytes = 131072
  session.timeout.ms = 10000
  ssl.cipher.suites = null
  ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
  ssl.endpoint.identification.algorithm = null
  ssl.key.password = null
  ssl.keymanager.algorithm = SunX509
  ssl.keystore.location = null
  ssl.keystore.password = null
  ssl.keystore.type = JKS
  ssl.protocol = TLS
  ssl.provider = null
  ssl.secure.random.implementation = null
  ssl.trustmanager.algorithm = PKIX
  ssl.truststore.location = null
  ssl.truststore.password = null
  ssl.truststore.type = JKS
  value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[run-main-0] INFO org.apache.kafka.common.utils.AppInfoParser: Kafka version : 1.0.1
[run-main-0] INFO org.apache.kafka.common.utils.AppInfoParser: Kafka commitId : c0518aa65f25317e
[run-main-0] INFO com.github.yandoroshenko.creativedock.kafka.GroupConsumer$: Subscribing for topic groups
java.lang.OutOfMemoryError: Java heap space
  at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
  at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)
  at org.apache.kafka.common.memory.MemoryPool$1.tryAllocate(MemoryPool.java:30)
  at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:140)
  at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
  at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
  at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
  at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:545)
  at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:483)
  at org.apache.kafka.common.network.Selector.poll(Selector.java:412)
  at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
  at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
  at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
  at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
  at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1146)
  at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1111)
  at com.github.yandoroshenko.creativedock.kafka.Consumer.$anonfun$watch$1(Consumer.scala:33)
  at com.github.yandoroshenko.creativedock.kafka.Consumer$$Lambda$2665/1014112742.apply$mcV$sp(Unknown Source)
  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
  at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:655)
  at scala.concurrent.Future$$$Lambda$2666/978354956.apply(Unknown Source)
  at scala.util.Success.$anonfun$map$1(Try.scala:251)
  at scala.util.Success.map(Try.scala:209)
  at scala.concurrent.Future.$anonfun$map$1(Future.scala:289)
  at scala.concurrent.Future$$Lambda$2667/168581268.apply(Unknown Source)
  at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
  at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
  at scala.concurrent.impl.Promise$$Lambda$2668/1908638899.apply(Unknown Source)
  at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
java.lang.OutOfMemoryError: Java heap space
  at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
  at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)
  at org.apache.kafka.common.memory.MemoryPool$1.tryAllocate(MemoryPool.java:30)
  at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:140)
  at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
  at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
  at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
  at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:545)
  at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:483)
  at org.apache.kafka.common.network.Selector.poll(Selector.java:412)
  at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
  at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
  at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
  at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
  at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
  at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1146)
  at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1111)
  at com.github.yandoroshenko.creativedock.kafka.Consumer.$anonfun$watch$1(Consumer.scala:33)
  at com.github.yandoroshenko.creativedock.kafka.Consumer$$Lambda$2665/1014112742.apply$mcV$sp(Unknown Source)
  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
  at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:655)
  at scala.concurrent.Future$$$Lambda$2666/978354956.apply(Unknown Source)
  at scala.util.Success.$anonfun$map$1(Try.scala:251)
  at scala.util.Success.map(Try.scala:209)
  at scala.concurrent.Future.$anonfun$map$1(Future.scala:289)
  at scala.concurrent.Future$$Lambda$2667/168581268.apply(Unknown Source)
  at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
  at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
  at scala.concurrent.impl.Promise$$Lambda$2668/1908638899.apply(Unknown Source)
  at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
java.net.SocketException: Permission denied
  at sun.nio.ch.Net.bind0(Native Method)
  at sun.nio.ch.Net.bind(Net.java:433)
  at sun.nio.ch.Net.bind(Net.java:425)
  at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
  at java.nio.channels.ServerSocketChannel.bind(ServerSocketChannel.java:157)
  at org.http4s.blaze.channel.nio1.NIO1SocketServerGroup.$anonfun$bind$1(NIO1SocketServerGroup.scala:63)
  at scala.util.Try$.apply(Try.scala:209)
  at org.http4s.blaze.channel.nio1.NIO1SocketServerGroup.bind(NIO1SocketServerGroup.scala:62)
  at org.http4s.server.blaze.BlazeBuilder.$anonfun$start$1(BlazeBuilder.scala:229)
  at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:74)
  at cats.effect.internals.IORunLoop$.start(IORunLoop.scala:34)
  at cats.effect.IO.unsafeRunAsync(IO.scala:193)
  at cats.effect.IO.$anonfun$runAsync$1(IO.scala:152)
  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
  at cats.effect.internals.IORunLoop$.step(IORunLoop.scala:154)
  at cats.effect.IO.unsafeRunTimed(IO.scala:222)
  at cats.effect.IO.unsafeRunSync(IO.scala:175)
  at fs2.StreamApp.main(StreamApp.scala:83)
  at com.github.yandoroshenko.creativedock.RestController.main(RestController.scala)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at sbt.Run.invokeMain(Run.scala:93)
  at sbt.Run.run0(Run.scala:87)
  at sbt.Run.execute$1(Run.scala:65)
  at sbt.Run.$anonfun$run$4(Run.scala:77)
  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
  at sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:10)
  at sbt.TrapExit$App.run(TrapExit.scala:252)
  at java.lang.Thread.run(Thread.java:745)

Exception: sbt.TrapExitSecurityException thrown from the UncaughtExceptionHandler in thread "run-main-0"
[error] java.lang.RuntimeException: Nonzero exit code: 1
[error]   at sbt.Run$.executeTrapExit(Run.scala:124)
[error]   at sbt.Run.run(Run.scala:77)
[error]   at sbt.Defaults$.$anonfun$bgRunTask$5(Defaults.scala:1169)
[error]   at sbt.Defaults$.$anonfun$bgRunTask$5$adapted(Defaults.scala:1164)
[error]   at sbt.internal.BackgroundThreadPool.$anonfun$run$1(DefaultBackgroundJobService.scala:366)
[error]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
[error]   at scala.util.Try$.apply(Try.scala:209)
[error]   at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:289)
[error]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
[error]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
[error]   at java.lang.Thread.run(Thread.java:745)
[error] (Compile / run) Nonzero exit code: 1
[error] Total time: 6 s, completed Mar 12, 2018 4:59:30 PM
